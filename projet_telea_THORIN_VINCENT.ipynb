{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f21c588",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed9805d",
   "metadata": {},
   "source": [
    "## Bibliothèques Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa161015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedGroupKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# libsigma\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from libsigma.read_and_write import (get_origin_coordinates,\n",
    "                                    load_img_as_array,\n",
    "                                    write_image,\n",
    "                                    get_image_dimension,\n",
    "                                    get_pixel_size,\n",
    "                                    open_image\n",
    "                                    )\n",
    "from libsigma.classification import get_samples_from_roi\n",
    "from libsigma.plots import plot_cm\n",
    "\n",
    "# my_function.py\n",
    "from my_function import rasterise_gdal, calcul_nari, plot_contrib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0cacf8",
   "metadata": {},
   "source": [
    "## Chemins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d14730",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = os.path.join(\"..\", \"results\")\n",
    "figures_dir = os.path.join(results_dir, \"figure\")\n",
    "data_dir = os.path.join(\"..\", \"data\", \"projet_eval\")\n",
    "img_dir = os.path.join(\".\", \"img\")\n",
    "\n",
    "os.makedirs(results_dir,exist_ok=True)\n",
    "os.makedirs(figures_dir,exist_ok=True)\n",
    "os.makedirs(img_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5591b33",
   "metadata": {},
   "source": [
    "# 4.2. Analyse des échantillons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ece993",
   "metadata": {},
   "source": [
    "## 4.2.1. Nombre d’échantillons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfadeae",
   "metadata": {},
   "source": [
    "### Nombre de polygones par classe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453c4733",
   "metadata": {},
   "source": [
    "#### Diagramme en bâtons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa4aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_path = os.path.join(\n",
    "    data_dir,\n",
    "    \"PI_strates_bretagne_32630.shp\"\n",
    ")\n",
    "\n",
    "echantillon_shp = gpd.read_file(shp_path)\n",
    "\n",
    "# Dictionnaire de référence car la liste des classes est connue d'avance \n",
    "labels_strates = {\n",
    "    1: \"Sol nu\",\n",
    "    2: \"Herbe\",\n",
    "    3: \"Landes\",\n",
    "    4: \"Arbre\"\n",
    "}\n",
    "\n",
    "# Compter et forcer les strates attendues\n",
    "counts = (\n",
    "    echantillon_shp[\"strate\"]\n",
    "    .value_counts()\n",
    "    .reindex(labels_strates.keys())\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "counts.plot(kind=\"bar\", ax=ax, color=\"green\")\n",
    "\n",
    "# Affiche les valeurs\n",
    "for i, val in enumerate(counts):\n",
    "    ax.text(i, val, int(val), ha=\"center\", va=\"bottom\") \n",
    "\n",
    "# Labels de l'axe X depuis le dictionnaire\n",
    "ax.set_xticklabels([f\"{s}\\n{labels_strates[s]}\" for s in counts.index], rotation=0)\n",
    "\n",
    "# Titres graphique et axes\n",
    "ax.set_title(\"Nombre de polygones échantillons par classes\")\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "\n",
    "# Sortie\n",
    "diag_baton_nb_poly_by_class = os.path.join(figures_dir, \"diag_baton_nb_poly_by_class.png\")\n",
    "\n",
    "plt.savefig(diag_baton_nb_poly_by_class,dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "print(\"Fichier créé :\", os.path.abspath(diag_baton_nb_poly_by_class))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c87c4",
   "metadata": {},
   "source": [
    "#### Commentaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdff6e7",
   "metadata": {},
   "source": [
    "On remarque que la distribution des échantillons est **déséquilibrée** : les landes sont la classe majoritaire tandis que **la classe « sol nu » est totalement absente**.\n",
    "\n",
    "Cela pourra poser des problèmes plus tard, notamment lors de la classification supervisée, en créant des **biais**. En effet, sans échantillon de référence dans cette classe, l'apprentissage sera impossible pour cette classe. Les résultats seront donc à interpréter avec prudence, particulièrement pour la classe « sol nu »."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c3f9db",
   "metadata": {},
   "source": [
    "### Nombre de pixels par classe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873bedb3",
   "metadata": {},
   "source": [
    "#### Contrôles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce385c1",
   "metadata": {},
   "source": [
    "Tout d'abord, on vérifie que tous nos fichiers de travail sont bien « **alignés** » : même résolution, même CRS, mêmes coordonnées à l'origine, mêmes dimensions. On utilise pour cela principalement des fonctions de ``libsigma``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661a5ebc",
   "metadata": {},
   "source": [
    "##### Résolution spatiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a433931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdal.DontUseExceptions() # supprime un avertissement par défaut de gdal\n",
    "\n",
    "# liste des rasters\n",
    "files = sorted(\n",
    "    f for f in os.listdir(data_dir)\n",
    "    if f.startswith(\"bretagne_24-25\")\n",
    ")\n",
    "\n",
    "pixel_sizes = [\n",
    "    get_pixel_size(\n",
    "        open_image(os.path.join(data_dir, f))\n",
    "    )\n",
    "    for f in files\n",
    "]\n",
    "\n",
    "if len(set(pixel_sizes)) == 1: # car un set supprime les doublons\n",
    "    print(\"✅ Toutes les images ont la même résolution. Taille des pixels :\", pixel_sizes[0])\n",
    "else:\n",
    "    print(\"❌ Les images n'ont PAS toutes la même résolution !\")\n",
    "    for f, ps in zip(files, pixel_sizes):\n",
    "        print(f, \":\", ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08350ee9",
   "metadata": {},
   "source": [
    "##### Système de projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f324a0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "crs_list = [\n",
    "    open_image(os.path.join(data_dir, f)).GetProjection()\n",
    "    for f in files\n",
    "]\n",
    "\n",
    "if len(set(crs_list)) == 1: # car un set supprime les doublons\n",
    "    print(\"✅ Toutes les images ont le même CRS :\", crs_list[0])\n",
    "else:\n",
    "    print(\"❌ Les images n'ont PAS toutes le même CRS\")\n",
    "    for f, crs in zip(files, crs_list):\n",
    "        print(f, \":\", crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eedc7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CRS du shapefile :\", echantillon_shp.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d765bd",
   "metadata": {},
   "source": [
    "Toutes les images ainsi que le shapefile sont projetés en WGS 84."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a861ba",
   "metadata": {},
   "source": [
    "##### Coordonnées du pixel à l'origine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf611a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "origins = [\n",
    "    get_origin_coordinates(\n",
    "        open_image(os.path.join(data_dir, f))\n",
    "    )\n",
    "    for f in files\n",
    "]\n",
    "\n",
    "if len(set(origins)) == 1: # car un set supprime les doublons\n",
    "    print(\"✅ Toutes les images ont la même origine :\", origins[0])\n",
    "else:\n",
    "    print(\"❌ Les images n'ont PAS la même origine\")\n",
    "    for f, origin in zip(files, origins):\n",
    "        print(f, \":\", origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcf6e6a",
   "metadata": {},
   "source": [
    "##### Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e32d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [\n",
    "    get_image_dimension(\n",
    "        open_image(os.path.join(data_dir, f))\n",
    "    )   # on ne garde que (nb_lignes, nb_colonnes)\n",
    "    for f in files\n",
    "]\n",
    "\n",
    "if len(set(dimensions)) == 1: # car un set supprime les doublons\n",
    "    print(\"✅ Toutes les images ont la même dimension :\", dimensions[0])\n",
    "else:\n",
    "    print(\"❌ Les images n'ont PAS toutes la même dimension\")\n",
    "    for f, dim in zip(files, dimensions):\n",
    "        print(f, \":\", dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bf1447",
   "metadata": {},
   "source": [
    "La fonction `get_image_dimension()` renvoie un triplet *(lignes, colonnes, bandes)*.\n",
    "\n",
    "Les dimensions spatiales (lignes et colonnes) sont identiques pour toutes les images, ce qui confirme leur bon alignement.\n",
    "\n",
    "En revanche, la présence de **6 bandes** par fichier est suspecte étant donné que **les images Sentinel-2 comportent 13 bandes** (dont on en sélectionne parfois 10).\n",
    "\n",
    "On comprend donc que ces 6 bandes correspondent aux **6 dates d’acquisition**, et non à des bandes spectrales. Les différentes bandes spectrales sont donc réparties entre plusieurs fichiers (ce qui est cohérent avec leur nom « ``BXX`` »), chacun empilant les informations temporelles.\n",
    "\n",
    "En l'état, le jeu de données fourni n'est **pas exploitable** car l’organisation des images est différente : **chaque fichier correspond à une bande spectrale** donnée, dans laquelle est « empilée » la **dimension temporelle**.\n",
    "\n",
    "Afin de pouvoir travailler sur ces fichiers, il est donc nécessaire de **réorganiser ces données**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f418bf",
   "metadata": {},
   "source": [
    "#### Réorganisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3a60cc",
   "metadata": {},
   "source": [
    "On fait l'**hypothèse** que l'ordre des bandes suit l'ordre chronologique des dates fournies dans l'énoncé, donc :\n",
    "\n",
    "- 2025-03-31 → Bande 1\n",
    "- 2025-04-10 → Bande 2\n",
    "- 2025-05-15 → Bande 3\n",
    "- 2025-06-17 → Bande 4\n",
    "- 2025-07-12 → Bande 5\n",
    "- 2025-08-10 → Bande 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc329e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [\n",
    "    \"2025-03-31\",\n",
    "    \"2025-04-10\",\n",
    "    \"2025-05-15\",\n",
    "    \"2025-06-17\",\n",
    "    \"2025-07-12\",\n",
    "    \"2025-08-10\"\n",
    "]\n",
    "\n",
    "bands = [\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B11\",\"B12\"]\n",
    "\n",
    "# Charge les 10 fichiers\n",
    "arrays_by_band = [\n",
    "    load_img_as_array(os.path.join(data_dir, f\"bretagne_24-25_{b}.tif\"))\n",
    "    for b in bands\n",
    "]\n",
    "\n",
    "img_ds = open_image(os.path.join(data_dir, f\"bretagne_24-25_{bands[0]}.tif\"))\n",
    "\n",
    "for t, date in enumerate(dates):\n",
    "    img_t = np.stack([arr[:, :, t] for arr in arrays_by_band], axis=2)\n",
    "\n",
    "    data_ready_dir = os.path.join(figures_dir, \"data_ready\")\n",
    "    os.makedirs(data_ready_dir,exist_ok=True) # Crée le dossier s'il n'existe pas\n",
    "    output_path = os.path.join(data_ready_dir, f\"bretagne_24-25_{date}.tif\")\n",
    "\n",
    "    write_image(\n",
    "        out_filename=output_path,\n",
    "        array=img_t,\n",
    "        data_set=img_ds\n",
    "    )\n",
    "\n",
    "    print(\"Fichier créé :\", os.path.abspath(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc35f0a",
   "metadata": {},
   "source": [
    "Ce code crée un nouveau dossier ``data_ready`` qui contient les images retravaillées : 10 bandes pour chacune des 6 dates.\n",
    "\n",
    "On vérifie que la manipulation s'est bien déroulée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf87833",
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in dates:\n",
    "    fname = f\"bretagne_24-25_{date}.tif\"\n",
    "    fpath = os.path.join(data_ready_dir, fname)\n",
    "\n",
    "    dims = get_image_dimension(open_image(fpath))\n",
    "    print(f\"{fname} → {dims}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd4e87b",
   "metadata": {},
   "source": [
    "#### Diagramme en bâtons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0e067",
   "metadata": {},
   "source": [
    "Pour **compter les pixels**, on peut choisir une image au hasard puisqu'on a vérifié qu'elles étaient toutes « alignées ».\n",
    "\n",
    "Pour **rasteriser** le shapefile, OTB n'est pas disponible dans cet environnement, on utilise donc **GDAL**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99325b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ref = os.path.join(data_ready_dir, \"bretagne_24-25_2025-03-31.tif\")\n",
    "echantillon_rasterize = os.path.join(figures_dir, \"echantillon_rasterize.tif\")\n",
    "\n",
    "rasterise_gdal(\n",
    "    shp_path=shp_path,\n",
    "    ref_image=image_ref,\n",
    "    out_raster=echantillon_rasterize,\n",
    "    attribute=\"strate\",\n",
    "    gdal_dtype=gdal.GDT_Float32\n",
    ")\n",
    "\n",
    "print(\"Fichier créé :\", os.path.abspath(echantillon_rasterize))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99ba822",
   "metadata": {},
   "source": [
    "La rasterisation a été réalisée selon la règle par défaut de GDAL, où un pixel est affecté à une classe si son centre est inclus dans le polygone. L’option ``ALL_TOUCHED`` n’a pas été utilisée afin d’éviter une surestimation des surfaces.\n",
    "\n",
    "C'est la raison pour laquelle on peut observer des « débordements » des polygones par rapport aux pixels (voir ci-dessous).\n",
    "\n",
    "<center>\n",
    "    <figure>\n",
    "    <img src=\"img/rasterisation.png\" width=\"200\">\n",
    "    <figcaption>Le polygone « déborde » à certains endroits<br/>car les centres des pixels associés ne tombent pas dans le polygone.</figcaption>\n",
    "    </figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e300b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, Y, _ = get_samples_from_roi(image_ref, echantillon_rasterize)\n",
    "\n",
    "values, counts = np.unique(Y, return_counts=True)\n",
    "\n",
    "counts_dict = dict(zip(values.flatten().tolist(), counts.tolist()))\n",
    "ordered_classes = list(labels_strates.keys())\n",
    "ordered_counts = [counts_dict.get(c, 0) for c in ordered_classes]\n",
    "ordered_labels = [labels_strates[c] for c in ordered_classes]\n",
    "\n",
    "plt.bar(ordered_labels, ordered_counts)\n",
    "for i, v in enumerate(ordered_counts):\n",
    "    plt.text(i, v, str(int(v)), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.title(\"Nombre de pixels échantillons par classe\")\n",
    "\n",
    "diag_baton_nb_pix_by_class = os.path.join(figures_dir, \"diag_baton_nb_pix_by_class.png\")\n",
    "plt.savefig(diag_baton_nb_pix_by_class, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "print(\"Fichier créé :\", os.path.abspath(diag_baton_nb_pix_by_class))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a13841",
   "metadata": {},
   "source": [
    "#### Commentaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54ee502",
   "metadata": {},
   "source": [
    "Ce diagramme met en évidence que **la classe « landes » occupe la surface la plus importante** (plus grand nombre de pixels).\n",
    "\n",
    "Comme les pixels sont de taille 10 × 10 mètres, nous avons les surfaces suivantes :\n",
    "\n",
    "- 10.22 hectares classés en « herbe »\n",
    "- 15.99 hectares classés en « landes »\n",
    "- 12.18 hectares classés en « arbre »\n",
    "\n",
    "En cohérence avec le diagramme précédent, nous n'avons **aucun pixel** dans la classe « sol nu ». Dans la suite de l'étude, nous **exclurons** donc cette classe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e339a63",
   "metadata": {},
   "source": [
    "## 4.2.2. Phénologie des strates, mise en évidence des landes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d5a14b",
   "metadata": {},
   "source": [
    "### Série temporelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad69de",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_ready = sorted(\n",
    "    f for f in os.listdir(data_ready_dir)\n",
    ")\n",
    "\n",
    "# Calcul du NARI pour chaque date\n",
    "nari_list = []\n",
    "for f in files_ready:\n",
    "    img_path = os.path.join(data_ready_dir, f)\n",
    "    img = load_img_as_array(img_path)\n",
    "\n",
    "    nari = calcul_nari(img, nodata=-9999)\n",
    "    nari_list.append(nari)\n",
    "\n",
    "# Empile les dates pour former une série temporelle\n",
    "nari_stack = np.stack(nari_list, axis=2).astype(\"float32\")\n",
    "\n",
    "# Référence : une image data_ready (garantit l'alignement de la sortie avec les entrées)\n",
    "ref_ds = open_image(os.path.join(data_ready_dir, files_ready[0]))\n",
    "\n",
    "output_name = os.path.join(results_dir, \"ARI_serie_temp.tif\")\n",
    "write_image(\n",
    "    out_filename=output_name,\n",
    "    array=nari_stack,\n",
    "    data_set=ref_ds,\n",
    "    gdal_dtype=gdal.GDT_Float32\n",
    ")\n",
    "\n",
    "# Définit la valeur de NoData car la fonction write_image ne le permet pas\n",
    "ds_out = gdal.Open(output_name, gdal.GA_Update)\n",
    "for i in range(1, ds_out.RasterCount + 1):\n",
    "    ds_out.GetRasterBand(i).SetNoDataValue(-9999)\n",
    "ds_out = None\n",
    "ref_ds = None\n",
    "\n",
    "print(\"Fichier créé :\", os.path.abspath(output_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e646e0b5",
   "metadata": {},
   "source": [
    "### Moyenne & écart-type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ae3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 5))\n",
    "\n",
    "dict_ARI, Y, t = get_samples_from_roi(\n",
    "    raster_name=os.path.join(results_dir, \"ARI_serie_temp.tif\"),\n",
    "    roi_name=echantillon_rasterize,\n",
    "    output_fmt=\"by_label\"\n",
    ")\n",
    "\n",
    "colors = ['blue', 'red', 'green']\n",
    "labels = ['Herbes', 'Landes', 'Arbres']\n",
    "\n",
    "for X, color, label in zip(dict_ARI.values(), colors, labels):\n",
    "    # X : (n_pixels, 6 dates)\n",
    "    means = X.mean(axis=0)\n",
    "    stds = X.std(axis=0)\n",
    "\n",
    "    ax.plot(means, color=color)\n",
    "    ax.fill_between(\n",
    "        range(len(means)),\n",
    "        means - stds,\n",
    "        means + stds,\n",
    "        facecolor=color,\n",
    "        alpha=0.3,\n",
    "        label=label\n",
    "    )\n",
    "\n",
    "ax.set_xticks(range(len(dates)))\n",
    "ax.set_xticklabels(dates, rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"ARI\")\n",
    "ax.set_title(\"Moyenne et écart-type de l'ARI des pixels échantillons\")\n",
    "ax.legend()\n",
    "ax.yaxis.grid(True, linestyle=\"--\", linewidth=0.6,color='gray')\n",
    "\n",
    "out_path = os.path.join(figures_dir, \"ARI_series.png\")\n",
    "plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "print(\"Fichier créé :\", os.path.abspath(out_path))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e60b3",
   "metadata": {},
   "source": [
    "#### Commentaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb30194",
   "metadata": {},
   "source": [
    "<u>Rappel de l'objectif</u> : « *étudier si la classe de landes se distingue des autres grâce au ARI et comment* »."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dadab75",
   "metadata": {},
   "source": [
    "Dans la période donnée, entre mars et août, l'ARI des landes varie **entre 0.12 et 0.16**, avec une diminution notable au cours des mois de mai-juin pour remonter au début de l'été.\n",
    "\n",
    "Les strates **herbes et landes** présentent des **valeurs d'ARI relativement proches** et leurs intervalles de variabilité (écart-types) se recouvrent partiellement, voire totalement en été.\n",
    "\n",
    "À un instant $t$, l'ARI est donc un **bon indicateur pour distinguer les landes des arbres**, mais il n'est **pas suffisant pour les distinguer des herbes**.\n",
    "\n",
    "En revanche, une **analyse temporelle** sur la période donnée permet de bien caractériser les landes : leur ARI est systématiquement **supérieur à celui des arbres** et la **chute** au mois de mai est **moins prononcée** que pour les herbes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50ce33f",
   "metadata": {},
   "source": [
    "# 4.3. Production d'une carte de strates à l'échelle du pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2ecaf",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bcccec",
   "metadata": {},
   "source": [
    "La première étape consiste à **construire le jeu de données d’apprentissage**, composé d’une matrice de variables explicatives $X$ et d’un vecteur de labels $y$ correspondant aux strates issues des polygones d’échantillonnage.\n",
    "\n",
    "Pour les **données en entrées** $X$, il y a plusieurs possibilités. On peut entraîner le modèle sur :\n",
    "1. L'ensemble des 10 bandes\n",
    "2. L'ensemble des 10 bandes + la bande NARI que nous avons créée précédemment\n",
    "3. Seulement les bandes qui interviennent dans le calcul du NARI (``B03`` et ``B05``)\n",
    "\n",
    "Nous allons ici préférer la **première option** :\n",
    "\n",
    "- En effet, la bande du **NARI est une combinaison de bandes** déjà existantes et le modèle pourra reconnaître le « ***pattern*** » qui a permis de construire cet indice (à condition de ne pas choisir un modèle linéaire, donc cohérent avec l'utilisation de RF). Le NARI n'est donc pas en soi une donnée explicative et nous allons donc l'exclure pour **limiter le bruit** lors de l'apprentissage.\n",
    "\n",
    "- De plus, l'utilisation de seulement deux bandes semble assez **limité** pour le but de ce projet (« *produire une carte des strates* »). Les bandes 3 (vert) et 5 (*red edge*) ont permis de calculer un indicateur concernant la présence d'anthocyanes, mais limiter l'apprentissage à ces bandes reviendrait à dire que la classification des strates **ne dépend que de celles-ci**. Or, on peut imaginer que d'**autres facteurs**, que le modèle va tenter de détecter, interviennent dans la différenciation des strates. Nous verrons par la suite la **contribution des variables**, c'est-à-dire à quel point chaque bande explique la classification dans telle ou telle strate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953820c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction des données d'apprentissage\n",
    "\n",
    "# Principe : on parcourt les dates, on extrait les bandes pour chaque date,\n",
    "# puis on les « empile » (np.hstack).\n",
    "\n",
    "X_list = []\n",
    "\n",
    "# On va boucler sur les 6 dates\n",
    "for date_image in files_ready:\n",
    "    image_by_date = os.path.join(data_ready_dir, date_image) # Chemin vers image à UNE date\n",
    "\n",
    "    # X_date : (n_pixels, 10) = valeurs des 10 bandes pour les pixels échantillons à cette date\n",
    "    # Y      : (n_pixels, 1)  = strate (labels) des mêmes pixels (issu du raster ROI)\n",
    "    X_date, Y, _ = get_samples_from_roi(\n",
    "        raster_name=image_by_date,\n",
    "        roi_name=echantillon_rasterize,\n",
    "    )\n",
    "\n",
    "    X_list.append(X_date)\n",
    "\n",
    "# Concaténation des 6 dates\n",
    "X = np.hstack(X_list)\n",
    "\n",
    "# Mise en forme des labels pour scikit learn\n",
    "y = Y[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17ac59",
   "metadata": {},
   "source": [
    "Ci-dessus, nous sommes passés d’une structure composée de **plusieurs matrices correspondant chacune à une date d’acquisition** à une matrice unique dans laquelle **chaque pixel est décrit par l’ensemble de ses variables spectrales** sur toutes les dates.\n",
    "\n",
    "Cela a été nécessaire pour entraîner le modèle en **intégrant la dimension temporelle** et non en l'entraînant à une date arbitraire (cela aurait des résultats significativement différents selon la saison).\n",
    "\n",
    "En résumé, **on concatène l'ensemble des valeurs spectrales à chaque date** dans un seul et même élément de la liste plutôt que de fournir au classifieur une succession de matrices indépendantes (bien que nous sachions qu'elles sont classées par date, le classifieur n'a aucune notion du temps), ce qui reviendrait à entraîner le modèle sur des observations à l'instant $t$ sans réelle prise en compte de la dynamique temporelle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7f382",
   "metadata": {},
   "source": [
    "## 4.3.1. Choix du classifieur et sa paramétrisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53f35be",
   "metadata": {},
   "source": [
    "Le classifieur imposé est **RandomForest** et nous devons **optimiser les hyperparamètres** selon le tableau suivant :\n",
    "\n",
    "|    Hyperparamètre    |    Valeurs     |\n",
    "|--------------------: | :----------------------|\n",
    "| ``n_estimators``     | ``50``, ``100``, ``150``, ``200``, ``300`` |\n",
    "| ``max_depth``        | ``None``, ``10``, ``15``, ``20``|\n",
    "| ``max_features``     | ``None``, ``sqrt``, ``log2``|\n",
    "| ``min_samples_leaf`` | ``1``, ``5``|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdb0cd6",
   "metadata": {},
   "source": [
    "## 4.3.2. Stratégie de validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eee7231",
   "metadata": {},
   "source": [
    "Afin de sélectionner la configuration parmi les 120 possibles qui donne les meilleures performances, ces hyperparamètres doivent être testés à l'aide d'une recherche sur grille (**GridSearchCV**) combinée à une validation croisée.\n",
    "\n",
    "Pour accélérer le temps de calcul, on parallélise les traitements (``n_jobs=-1``).\n",
    "\n",
    "On choisit la stratégie ***StratifiedGroupKFold*** car on a ici un certain **déséquilibre** entre le nombre de pixels d'entraînement selon les classes et il est nécessaire de conserver des **proportions** comparables. On voudrait également **grouper les pixels** selon le polygone auquel ils appartiennent pour **affiner le modèle**.\n",
    "\n",
    "On constate cependant que le champ ``id`` du shapefile n'est **pas unique** pour chaque polygone :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd1534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "echantillon_shp[\"id\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3f3043",
   "metadata": {},
   "source": [
    "Il est donc nécessaire de **réattribuer un identifiant unique** pour chaque polygone :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "echantillon_shp[\"id_unique\"] = range(1, len(echantillon_shp) + 1)\n",
    "\n",
    "echantillon_shp[[\"id\", \"id_unique\"]]\n",
    "\n",
    "shp_id_unique = os.path.join(\"..\", \"data\", \"projet_eval\", \"bretagne_id_unique.shp\")\n",
    "\n",
    "echantillon_shp.to_file(shp_id_unique)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616aad92",
   "metadata": {},
   "source": [
    "que l'on rasterise également pour identifier les différents groupes qui serviront à la cross-validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b00f84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "echantillon_id_unique = os.path.join(figures_dir, \"echantillon_id_unique.tif\")\n",
    "\n",
    "rasterise_gdal(\n",
    "    shp_path=shp_id_unique,\n",
    "    ref_image=image_ref,\n",
    "    out_raster=echantillon_id_unique,\n",
    "    attribute=\"id_unique\",\n",
    "    gdal_dtype=gdal.GDT_Int32\n",
    ")\n",
    "\n",
    "print(\"Fichier créé :\", echantillon_id_unique)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d177e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_id, _, _ = get_samples_from_roi(\n",
    "    raster_name=echantillon_id_unique,\n",
    "    roi_name=echantillon_rasterize\n",
    ")\n",
    "\n",
    "# Définition du vecteur de groupes\n",
    "groups = X_id[:, 0].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d40282",
   "metadata": {},
   "source": [
    "On peut maintenant utiliser ``GridSearchCV`` selon la méthode *StratifiedGroupKFold*. On se base sur la métrique **``F1-macro``** qui calcule un score indépendamment sur chaque classe, ce qui le rend moins sensible aux déséquilibres (chaque classe compte « autant »).\n",
    "\n",
    "La valeur de $k$ (``n_splits=5``) est un **compromis** entre la robustesse de l'estimation des performances et le temps de calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c70304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RF(random_state=0)\n",
    "\n",
    "# Grille des valeurs d'hyperparamètres à tester\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 150, 200, 300],\n",
    "    \"max_depth\": [None, 10, 15, 20],\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"],\n",
    "    \"min_samples_leaf\": [1, 5],\n",
    "}\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1_macro\",\n",
    "    n_jobs=-1,\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "grid.fit(X, y, groups=groups)\n",
    "\n",
    "print(\"\\nMeilleurs hyperparamètres :\")\n",
    "print(grid.best_params_)\n",
    "print(f\" avec un score moyen (f1_macro) de : {grid.best_score_:.3f}\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Temps d'exécution : environ 6 min 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8046b0",
   "metadata": {},
   "source": [
    "*Note : le code ci-dessus met au maximum 7 minutes à s'exécuter.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52e89d9",
   "metadata": {},
   "source": [
    "## 4.3.3. Contribution des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b756ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = best_model.feature_importances_\n",
    "\n",
    "# Création des labels (concaténation Bande_Date)\n",
    "labels = []\n",
    "for d in dates:\n",
    "    for b in bands:\n",
    "        labels.append(f\"{b}_{d}\")\n",
    "\n",
    "# Tri décroissant\n",
    "idx_sorted = np.argsort(importances)[::-1]\n",
    "importances_sorted = importances[idx_sorted]\n",
    "labels_sorted = [labels[i] for i in idx_sorted]\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.bar(np.arange(len(importances_sorted)), importances_sorted)\n",
    "plt.title(\"Importance des variables\")\n",
    "\n",
    "plt.xticks(\n",
    "    np.arange(len(labels_sorted)),\n",
    "    labels_sorted,\n",
    "    rotation=90,\n",
    "    fontsize=8\n",
    ")\n",
    "\n",
    "# Suppression des marges vides\n",
    "plt.margins(x=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5e2624",
   "metadata": {},
   "source": [
    "Cet histogramme **exhaustif**  affiche les contributions de l'ensemble des 60 variables ``BXX_Date``. Ci-dessous les 10 variables les plus importantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a65452",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importance = pd.DataFrame({\n",
    "    \"Variable\": labels,\n",
    "    \"Importance\": importances\n",
    "})\n",
    "\n",
    "df_importance_tri = df_importance.sort_values(\n",
    "    by=\"Importance\",\n",
    "    ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "df_importance_tri.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab5919",
   "metadata": {},
   "source": [
    "En observant les dix variables les plus explicatives, on remarque que les **bandes ``05``, ``06``, ``07`` et ``08``** reviennent plus que les autres. \n",
    "\n",
    "De plus, les 5 premières variables explicatives datent toutes du **printemps**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858ec04e",
   "metadata": {},
   "source": [
    "Mais ces informations ne nous permettent pas de dégager une **tendance** (bandes et dates se « mélangent »). Affichons donc les contributions de chaque bande et de chaque date, dont les diagrammes seront plus parlants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53046ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "plot_contrib(\n",
    "    importances=importances,\n",
    "    bands=bands,\n",
    "    dates=dates,\n",
    "    mode=\"bands\",\n",
    "    ax=axes[0]\n",
    ")\n",
    "\n",
    "plot_contrib(\n",
    "    importances=importances,\n",
    "    bands=bands,\n",
    "    dates=dates,\n",
    "    mode=\"dates\",\n",
    "    ax=axes[1]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469dd29e",
   "metadata": {},
   "source": [
    "De manière générale, il semble que la **date d'acquisition soit plus importante que le numéro de la bande**, particulièrement au printemps (mars et avril).\n",
    "\n",
    "On peut également remarquer que l'importance des bandes est relativement **équilibrée**, ce qui confirme que nous avons fait le bon choix de ne pas entraîner notre modèle uniquement sur les bandes ``03`` et ``05``.\n",
    "\n",
    "La dimension temporelle apporte donc une information **complémentaire** pour identifier la végétation. Cela s'explique par le cycle de vie des plantes, la saison, etc. Le  modèle s'appuie sur ces différences saisonnières pour améliorer les distinctions entre les classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee71982b",
   "metadata": {},
   "source": [
    "## 4.3.4. Production des cartes finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb39667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X, y) # Entraînement du modèle sur tous les échantillons\n",
    "\n",
    "ref_ds = gdal.Open(image_ref)\n",
    "lignes, cols = ref_ds.RasterYSize, ref_ds.RasterXSize\n",
    "\n",
    "X_img_list = []\n",
    "valid_mask = None  # masque des pixels valides\n",
    "\n",
    "for tif_name in files_ready:\n",
    "    tif_path = os.path.join(data_ready_dir, tif_name)\n",
    "\n",
    "    img = load_img_as_array(tif_path)\n",
    "    r, c, n_bands = img.shape\n",
    "\n",
    "    X_date = img.reshape(lignes * cols, n_bands)\n",
    "    X_img_list.append(X_date)\n",
    "\n",
    "    # on créé un masque pour éliminer les pixels = 0 ou avec erreur (ex : valeur infinie) \n",
    "    v = np.isfinite(X_date).all(axis=1) & (X_date != 0).all(axis=1)\n",
    "    valid_mask = v if valid_mask is None else (valid_mask & v)\n",
    "\n",
    "# concaténation temporelle\n",
    "X_map = np.hstack(X_img_list)\n",
    "\n",
    "y_flat = np.zeros(lignes * cols, dtype=np.uint8)\n",
    "\n",
    "# prédiction uniquement sur pixels valides\n",
    "y_flat[valid_mask] = best_model.predict(X_map[valid_mask]).astype(np.uint8)\n",
    "\n",
    "y_map = y_flat.reshape(lignes, cols)\n",
    "\n",
    "out_filename = os.path.join(results_dir, \"carte_strates.tif\")\n",
    "\n",
    "write_image(\n",
    "    out_filename=out_filename,\n",
    "    array=y_map,\n",
    "    data_set=ref_ds,\n",
    "    gdal_dtype=gdal.GDT_Byte # uint8 pour gdal\n",
    ")\n",
    "\n",
    "# déclaration nodata, pas possible avec write_image\n",
    "ds_out = gdal.Open(out_filename, gdal.GA_Update)\n",
    "ds_out.GetRasterBand(1).SetNoDataValue(0)\n",
    "ds_out = None\n",
    "ref_ds = None\n",
    "\n",
    "print(\"Fichier créé :\", os.path.abspath(out_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08594b9b",
   "metadata": {},
   "source": [
    "## 4.3.5. Analyse des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e36519",
   "metadata": {},
   "source": [
    "On **sépare les données d'entraînement et de test** pour ne pas qu'un pixel entraîné soit également dans le test (ce qui biaiserait les résultats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd4ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=0)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Matrice\n",
    "labels_order = np.sort(np.unique(y_test))\n",
    "labels_text = [labels_strates[int(l)] for l in labels_order]\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels_order)\n",
    "\n",
    "plot_cm(cm,labels_text)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6dae0e",
   "metadata": {},
   "source": [
    "Le modèle présente une **très bonne qualité** globale. Les performances sont élevées pour l'ensemble des classes, avec des F1-scores compris entre 95 voire 98 %.\n",
    "\n",
    "La **diagonale** de la matrice de confusion est largement dominante, indiquant que la majorité des pixels sont correctement prédits.\n",
    "\n",
    "La classe « **herbe** » est la mieux prédite :\n",
    "\n",
    "- *Excellent pourcentage de précision*, donc très peu de faux positifs (seulement 3 pixels classés en herbe sont mal classés, soit 1 %).\n",
    "- Quelques confusions marginales avec les landes (8 pixels), mais aucune avec les arbres.\n",
    "\n",
    "Il s'agit donc de la classe **la plus reconnaissable**, à la fois en termes de justesse (précision) et d'exhaustivité (rappel).\n",
    "\n",
    "Les classes « **landes** » et « **arbres** » ont un comportement similaire :\n",
    "\n",
    "- Quelques pixels ont été mal prédits d'une classe vers l'autre.\n",
    "- Très peu de confusion avec l'herbe.\n",
    "\n",
    "Il est intéressant de noter qu'exactement le même nombre de pixels landes ont été classés en arbres et réciproquement (17). Il s'agit d'une coïncidence mais cela montre que le modèle s'est trompé autant de fois sur l'une que sur l'autre, renforçant l'idée que ces deux classes sont **plus difficiles à distinguer**.\n",
    "\n",
    "En effet, ces strates correspondent souvent à des états intermédiaires ou à des zones de transition écologique, où la structure de la végétation peut **varier de façon progressive** dans l'espace. Il peut donc être plus difficile de discriminer pixel par pixel une zone arborée d'une zone de végétation basse (puisque le modèle n'a aucune indication de hauteur).\n",
    "\n",
    "L'herbe, en revanche, possède avec une structure plus simple et plus homogène, ce qui facilite sa reconnaissance par le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e62d0",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519a454f",
   "metadata": {},
   "source": [
    "## Données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f7a0b7",
   "metadata": {},
   "source": [
    "La principale limite de notre analyse réside dans l'**absence de la classe « sol nu »** dans les données d'entraînement. Celle-ci n'a donc pas été apprise et donc prédite par le modèle. Dans l'idée, cela revient à dire que si aucun pixel d'échantillon n'est du sol nu, alors aucun pixel de l'image ne l'est. Cependant, les échantillons représentent 0.04 % de l'ensemble des pixels $\\left(\\frac{3\\,839}{938\\,196} \\right)$ et on peut raisonnablement penser que dans le reste de l'image (99.96 %), on pourrait trouver du sol nu. Ce point montre donc l'importance du **choix des échantillons** à fournir au modèle. Un déséquilibre entre des classes n'est pas un gros problème si l'on utilise un algorithme stratifié, en revanche aucun modèle ne peut prédire une classe dont il ne sait même pas qu'elle existe…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005dcbfa",
   "metadata": {},
   "source": [
    "Une autre limitation connexe concerne les **strates imposées** par le sujet. Bien que l'étude se déroule dans une zone naturelle, on y trouve des routes, des bâtiments et d'autres infrastructures humaines qui sont **inclassables** avec la typologie fournie. On voit d'ailleurs que le modèle semble « perdu » lorsqu'il doit prédire dans une zone urbanisée : non seulement il prédit mal (il n'a pas le choix !), mais en plus il « tente » les trois classes possibles de manière incohérente :\n",
    "\n",
    "<center>\n",
    "    <figure>\n",
    "    <img src=\"img/zone_urb.png\" width=\"500\">\n",
    "    <figcaption>Beaucoup de couleurs dans cette zone construite…</figcaption>\n",
    "    </figure>\n",
    "</center>\n",
    "\n",
    "Ici le modèle a prédit un arbre alors qu'il prédisait des landes sur tout le reste de la route :\n",
    "\n",
    "<center>\n",
    "    <figure>\n",
    "    <img src=\"img/ilot_arbre.png\" width=\"200\">\n",
    "    <figcaption>Un pixel « arbre » au milieu d'un océan de landes !</figcaption>\n",
    "    </figure>\n",
    "</center>\n",
    "\n",
    "Une classe « sol nu » aurait sans doute amélioré cela (notamment pour les routes), mais elle n'aurait pas été très utile pour détecter les bâtiments par exemple. Le nombre de classes imposé était donc assez restreint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4d1c60",
   "metadata": {},
   "source": [
    "## Interprétation des contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f39441",
   "metadata": {},
   "source": [
    "Nous avons vu que la période d'acquisition des données pour entraîner le modèle est autant voire plus importante que les signatures spectrales.\n",
    "\n",
    "En réalité, ce résultat doit être interprété **avec prudence**. Les **dynamiques saisonnières** de la végétation, bien qu’elles suivent des cycles annuels, ne sont pas parfaitement régulières. Des **variations climatiques**, comme un hiver plus doux que la moyenne, une canicule, des précipitations intenses, peuvent modifier le comportement de la végétation, donc sa représentation sur les bandes spectrales, donc sa reconnaissance par le modèle.\n",
    "\n",
    "Il est donc important de combiner la dimension temporelle avec les bandes spectrales car elles sont **complémentaires** et permettent de cerner plus précisément les comportements saisonniers des végétaux. Cependant nous avons vu que l'analyse combinée des variables contributives ne permettait pas de dégager une tendance. Il y a donc un **arbitrage** à faire entre la richesse des informations et la lisibilité. De manière générale, **la recherche de l'exactitude empêche une bonne interprétation des résultats** (c'est également vrai pour le sur-apprentissage)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1679b58f",
   "metadata": {},
   "source": [
    "## Limitations de la carte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095089dc",
   "metadata": {},
   "source": [
    "La carte finale est produite par pixel de 10 mètres. Il s'agit évidemment d'une représentation schématique, mais cela génère des **incohérences** telles que des îlots, des discontinuités, etc.\n",
    "\n",
    "Un moyen de rendre la carte plus cohérente serait, si c'est possible, de donner au modèle des **contraintes spatiales**. Cela dit, le modèle perdrait inévitablement en précision.\n",
    "\n",
    "Cette problématique se retrouve dans les différentes approches entre par exemple l'OSO, basée sur une **classification fine mais pixelisée**, et des référentiels tels que l'OCSGE, avec une approche par des polygones, plus **cohérente mais simplifiée**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d31c17",
   "metadata": {},
   "source": [
    "Malgré ces limites, la carte reste **pertinente** pour des analyses **à moyenne échelle**, par exemple pour étudier la distribution des strates végétales ou pour des comparaisons dans le temps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac075d9",
   "metadata": {},
   "source": [
    "## Perspectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7296c5d",
   "metadata": {},
   "source": [
    "Pour notre cas en Bretagne où nous n'avions pas de sol nu, nous aurions pu affiner notre analyse en nous basant sur un **Modèle Numérique d'Élévation**. En effet, les trois classes à prédire représentent de la végétation chacun à une hauteur relativement distincte (herbe = basse, landes = moyenne, arbres = haute). Insérer un raster de MNE dans les données d'entraînement aurait permis au modèle de prendre cette variable en compte (il serait alors intéressant d'observer la contribution de l'élévation dans la prédiction du modèle)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
